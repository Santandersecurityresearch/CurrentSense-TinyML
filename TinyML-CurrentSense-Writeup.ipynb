{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legitimate-operator",
   "metadata": {},
   "source": [
    "# Detecting Microcontroller Behaviour w/ Current Sensing and TinyML\n",
    "\n",
    "Welcome to this example and tutorial for using TinyML and current sensing to work out what is going on on a target PCB. This example is designed to be a full walkthrough for each stage of the process:\n",
    "* Setting up the circuits for us to measure current from the target.\n",
    "* Generating training data for our ML model\n",
    "* Training the ML Model with TensorFlow and Keras\n",
    "* Quantizing the ML Model with TensorFlow Lite\n",
    "* Loading the ML Model onto a microcontroller\n",
    "* Using the current sensing side channel to determine if an LED is on or off\n",
    "\n",
    "This work is inspired by prior work I have done, as well as the work of [@stacksmashing](https://twitter.com/stacksmashing) at Level Down security. This work is intended to be a worked Proof of Concept (PoC) for what is the next logical step in these kinds of attacks - using Machine Learning (ML) in current monitoring side-channel analysis attacks. \n",
    "\n",
    "**GOAL** - To detect an LED flashing on a target using an TensorFlow Lite ML model running on a different microcontroller speaking to an INA219 power monitor that is reading the power going into the target. \n",
    "\n",
    "First we shall setup our environment. We note that TensorFlow **does not support python v3.9.x**, so if you need to, you should run `conda activate` to enable a python 3.8.x environment. We first install TensorFlow and then do our imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "residential-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip -q install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lasting-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow is  the open source machine learning library we shall use\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras is TensorFlow's high-level API for deep learning\n",
    "from tensorflow import keras\n",
    "# Numpy is a math library\n",
    "import numpy as np\n",
    "# Pandas is a data manipulation library \n",
    "import pandas as pd\n",
    "# Matplotlib is a graphing library\n",
    "import matplotlib.pyplot as plt\n",
    "# Math is Python's math library\n",
    "import math\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-forestry",
   "metadata": {},
   "source": [
    "## Can this work? \n",
    "\n",
    "Despite prior evidence that says 'yes!' from the work we cited above, there are a few good indicators that this should work. If we setup the INA219 with the Nano 33 Sense and just monitor the Nano target running `blink`, we can see the following output when we use Arduino IDE's Serial Plotter (using the `get_current_data.ino` code for thsoe who want to play along at home):\n",
    "\n",
    "![initial motivation](media/currentsense-ML-init.png)\n",
    "\n",
    "We can see clearly when the LED is on - _hint_, it's when there's more power being used! This is only a difference of a few mA (the scale is roughly 10uA per y-increase of 1 in the graph). We also see a lot of noise in the output - where the current reading from the INA219 drops to zero in some position of the 16 numbers we are getting in the output. \n",
    "\n",
    "Machine Learning is pretty good at dealing with noise - in fact, it's a _de facto_ selling point of the tech. So in theory, this should have a good chance of working, we just need the following things:\n",
    "1. A good set of training data...\n",
    "1. The model to be trained!\n",
    "1. To deploy the model to a microcontroller. \n",
    "\n",
    "## But Why Machine Learning? \n",
    "\n",
    "You might ask **\"Why not just ask if the current is >15mA? That seems to be the logic we need...\"** and that is an _excellent_ question! This is just a PoC to show that this can be done - but also, if it works for this in terms of 'current usage pattern recognition', then it can possibly work for recognising more than 2 patterns (LED ON/LED OFF). So this should serve as a jumping off point for further work and refinements. :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-packet",
   "metadata": {},
   "source": [
    "# Setting Up and Getting Training Data\n",
    "\n",
    "Ok, so we've convinced ourselves that this _should_ work... or _might_ work... or _could_ work... so let's get started! \n",
    "\n",
    "## Bill of Materials\n",
    "\n",
    "This tutorial is designed for the following of materials:\n",
    "1. INA219 Current Measuring over I2C board\n",
    "1. Arduino Nano ATMEGA328P target board\n",
    "1. Arduino Nano 33 Sense ML capable board \n",
    "1. USB Cables and Laborkabel\n",
    "1. A Breadboard is handy\n",
    "1. Support for your target board and the Arduino Nano 33 Sense board in Arduino IDE\n",
    "1. The `Adafruit_INA219` library installed in Arduino IDE (using `Manage Libraries...`)\n",
    "\n",
    "## Generation of Training Data\n",
    "\n",
    "We want to measure the current going to the target using the INA219, so we'll use the following schematic:\n",
    "\n",
    "![Schematic of circuit](media/currentsense-ML-schematic.png)\n",
    "\n",
    "Let's break down what is going on here - the Arduino Nano Sense is the main event, providing power for the target and INA219 board from the USB We're powering the target from the Arduino Nano Sense via the sense screw terminal on the INA219 breakout board I'm using. \n",
    "\n",
    "The target is an Arduino Nano clone (using the cheap ones as targets as, well, they might break!). This is going to run the default `blink` example code.\n",
    "\n",
    "The eventual setup I have looks like this:\n",
    "\n",
    "![photo of setup](media/currentsense-ML-photo.jpeg)\n",
    "\n",
    "We can now collect some data! So how are we going to do this? Well, here is the rough plan of action:\n",
    "1. Setup a data collection firmware on the Nano 33 Sense.\n",
    "1. Setup two target firmwares:\n",
    "  1. One for the LED being on - `LED_on.ino`\n",
    "  1. One for the LED being off - `LED_off.ino`\n",
    "1. Gather training data for each - at least 5k samples.\n",
    "1. Manipulate the data to make it suitable for TensorFlow. \n",
    "\n",
    "## Target Code Snippets\n",
    "\n",
    "First up, load the `LED_off.ino` example to the target, and the `get_current_data.ino` to the Nano 33 Sense using the Arduino IDE for both (it's a bit of a pain, but if we do this right, we only have to do it a few times! :-P )\n",
    "\n",
    "Let's look at what each of these does. `LED_off.ino` is the following code: \n",
    "```c\n",
    "void setup() {\n",
    "  pinMode(LED_BUILTIN, OUTPUT);\n",
    "}\n",
    "\n",
    "void loop() {\n",
    "  digitalWrite(LED_BUILTIN, LOW);\n",
    "  delay(1000);  \n",
    "}\n",
    "```\n",
    "\n",
    "This code is fairly standard - it just turns the LED on, and monitoring the current from this will generate our 'LED is ON' trainig data from the `get_current_data.ino` firmware. \n",
    "\n",
    "**But why the `delay(1000);`?** - Well, my reasoning is as follows; the target code is going to be blinking the LED using the same delay function. We know from the work and products such as the ChipWhisperer from [NewAE](https://www.newae.com/) that current sensing is a very accurate side channel. Although we aren't going to be going 'full tilt' analysis on this target, just having the uC loop without the delay loop might give us some different behaviour (you can try it out to see if this is the case!!). So, in the interest of giving a reasonable example of \"how to generate training data\", I've included it here. \n",
    "\n",
    "We likewise use similar code for getting an 'LED is on' training set:\n",
    "\n",
    "```c\n",
    "void setup() {\n",
    "  pinMode(LED_BUILTIN, OUTPUT);\n",
    "}\n",
    "\n",
    "void loop() {\n",
    "  digitalWrite(LED_BUILTIN, HIGH);\n",
    "  delay(1000);  \n",
    "}\n",
    "```\n",
    "\n",
    "This code isn't really all that exciting, though... what we really want to look at is the code to...\n",
    "\n",
    "## Get Current Measurement Training Data\n",
    "\n",
    "So let's look at the code that analyses the current using the INA219! We'll go through this section by section...\n",
    "\n",
    "First up is this, well, _dirty hack_... \n",
    "\n",
    "```c\n",
    "// Dirrrrty Haxx...\n",
    "#define private public\n",
    "#define protected public\n",
    "```\n",
    "Yeah, just so it is said, **NEVER EVER DO THIS IN PRODUCTION** because that would just be _BAD_... But there is a reason for my madness here: I'm a lazy hacker. \n",
    "\n",
    "We will be using the `Adafruit_INA219` library (which you can install using the `Manage Libraries...` dialogue in the Arduino IDE). However, I want to access the raw `int16` output from the I2C bus from the INA219 chip. There _is_ a method in the Adafruit library for this; `Adafruit_INA219.getCurrent_raw()` - but this is a `private` method that is inaccessible in normal usage. \n",
    "\n",
    "Now, I _could_ write a load of I2C code, which I've done before, that would implement the I2C commands to the INA219 chip based [on the datasheet](https://www.ti.com/lit/ds/symlink/ina219.pdf?ts=1615929778308&ref_url=https%253A%252F%252Fwww.google.com%252F). That would be kinda fun as an exercise, but Adafruit have done the hard work for me, I just need to expose the method so I can use it... \n",
    "\n",
    "Thus, writing one line `#define private public` to override the class definition is much easier than writing >100 lines of I2C handler code. Like I said... _lazy hacker_... **DO NOT LET INTO PRODUCTION!**\n",
    "\n",
    "The next bit is fairly sedentry setup stuff:\n",
    "```c\n",
    "#include <Wire.h>\n",
    "#include <Adafruit_INA219.h>\n",
    "\n",
    "Adafruit_INA219 ina219;\n",
    "\n",
    "int16_t curr_array[16];\n",
    "int i;\n",
    "\n",
    "void setup(void) \n",
    "{\n",
    "  Serial.begin(115200);\n",
    "  while (!Serial) {\n",
    "      // will pause Zero, Leonardo, etc until serial console opens\n",
    "      delay(1);\n",
    "  }\n",
    "\n",
    "  uint32_t currentFrequency;\n",
    "    \n",
    "  Serial.println(\"Hello!\");\n",
    "\n",
    "  if (! ina219.begin()) {\n",
    "    Serial.println(\"Failed to find INA219 chip\");\n",
    "    while (1) { delay(10); }\n",
    "  }\n",
    "  // To use a slightly lower 32V, 1A range (higher precision on amps):\n",
    "  //ina219.setCalibration_32V_1A();\n",
    "  // Or to use a lower 16V, 400mA range (higher precision on volts and amps):\n",
    "  //ina219.setCalibration_16V_400mA();\n",
    "\n",
    "  Serial.println(\"Measuring voltage and current with INA219 ...\");\n",
    "}\n",
    "```\n",
    "Nothing really exciting there. We start the UART `Serial` handler, and initialise the INA219. All good! Now we get to the loop:\n",
    "```c\n",
    "void loop(void) \n",
    "{\n",
    "\n",
    "  for(i=0;i<16;i++){\n",
    "    curr_array[i] = ina219.getCurrent_raw();\n",
    "  }\n",
    "\n",
    "  Serial.print(\"[\");\n",
    "  for(i=0; i<15; i++){\n",
    "    Serial.print(curr_array[i]);\n",
    "    Serial.print(\",\");\n",
    "  }\n",
    "  Serial.print(curr_array[15]);\n",
    "  Serial.println(\"]\");\n",
    "}\n",
    "```\n",
    "\n",
    "So let's break this down - Let's start with the acquisition loop:\n",
    "```c\n",
    "  for(i=0;i<16;i++){\n",
    "    curr_array[i] = ina219.getCurrent_raw();\n",
    "  }\n",
    "```\n",
    "This loop gathers data from the INA219. It's kinda important that this is _always done the same way_! If we change this out, by, say, just outputting the bytes once per loop, then if we change the way we do things later, with different length loops on differently clocked microcontrollers, then we will have problems. So this is how we will acquire the data later on when we use the ML model for inference. \n",
    "\n",
    "The next block of code is the data output:\n",
    "```c\n",
    "  Serial.print(\"[\");\n",
    "  for(i=0; i<15; i++){\n",
    "    Serial.print(curr_array[i]);\n",
    "    Serial.print(\",\");\n",
    "  }\n",
    "  Serial.print(curr_array[15]);\n",
    "  Serial.println(\"]\");\n",
    "```\n",
    "This code outputs something along the lines of:\n",
    "`[125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125]`\n",
    "**But why the square brackets?** Well, again, this is me being lazy. If we take a string output like the above, then we can just run in python:\n",
    "```python\n",
    "data_str = \"[125,125,125,125,125,125,125,125,125,125,125,125,125,125,125,125]\"\n",
    "data = eval(data_str)\n",
    "```\n",
    "...and we will have a nice python array of numbers ready to go :) We can then load this easily into \n",
    "\n",
    "With this code ready, let's carry out our data acquisition plan!\n",
    "\n",
    "\n",
    "## Training Data Acquisition\n",
    "\n",
    "Doesn't that all sound so _fancy_?!? It's just us using the code we've discussed above and putting the data into files. So here's the plan:\n",
    "1. Load the `get_current_data.ino` firmware onto the Arduino Nano 33 Sense. \n",
    "1. Load `LED_off.ino` onto the target\n",
    "1. Power the circuit and run the following command (for linux or sim): `sudo screen -L -Logfile led-off.log /dev/ttyACM0 9600`\n",
    "1. When you have over 5k lines from this, power off the circuit\n",
    "1. Load `LED_on.ino` onto the target\n",
    "1. Power the circuit as before and run: `sudo screen -L -Logfile led-on.log /dev/ttyACM0 9600`\n",
    "1. Have a cuppa...\n",
    "\n",
    "We now have our data for 'LED is ON' and 'LED is OFF'! So let's begin the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-dominican",
   "metadata": {},
   "source": [
    "# Training the TensorFlow Model\n",
    "\n",
    "Well, now we have data (we've included copies of our own here), we will now setup and train our machine learning model using TensorFlow. First up, some utility functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "# This will convert our file of [1..16] strings to python lists to a numpy array that is TF friendly...\n",
    "def file_to_np(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        f_lines = f.readlines()\n",
    "    f_list = list(map(eval, f_lines))\n",
    "    f_np = np.array([np.array(fi) for fi in f_list])\n",
    "    return f_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-dancing",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "Next up, we will load the data into some variable arrays that we will use for training in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exciting-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_pochs = 1500\n",
    "\n",
    "num_samples = 5000\n",
    "train_size = int(num_samples * 0.6)\n",
    "test_size = int(num_samples * 0.2)\n",
    "validate_size = int(num_samples * 0.2) # we let model.fit() do this for us... just define this for now. -MC\n",
    "\n",
    "# Load the data files... EDIT for your own data! -MC\n",
    "f_ledoff = file_to_np('example_data/led-off2.log')[:num_samples]\n",
    "f_ledon = file_to_np('example_data/led-on2.log')[:num_samples]\n",
    "\n",
    "# Setup the training data...\n",
    "train_data = []\n",
    "training_data = []\n",
    "training_labels = []\n",
    "train_data.append(f_ledoff[:train_size])\n",
    "train_data.append(f_ledon[:train_size])\n",
    "for i in range(2):\n",
    "    for j in range(train_size):\n",
    "        training_labels.append(i) # Given we process the files sequentially, assign labels 0, 1, ...\n",
    "                                  # to the data from each file sequentially...\n",
    "        training_data.append(train_data[i][j])\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "# Set aside the test data - this will be used after training to see how we did...\n",
    "t_data = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "t_data.append(f_ledoff[train_size:(num_samples - validate_size)])\n",
    "t_data.append(f_ledon[train_size:(num_samples - validate_size)])\n",
    "for i in range(2):\n",
    "    for j in range(test_size):\n",
    "        test_labels.append(i)\n",
    "        test_data.append(t_data[i][j])\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# We can also add valdiation data - used to assess the model's efficacy during training,\n",
    "# but we don't use that here, as we let model.fit() do that for us.. but we _could_ define it ... -MC\n",
    "#v_data = []\n",
    "#validate_data = []\n",
    "#validate_labels = []\n",
    "#v_data.append(f_ledoff[validate_size:])\n",
    "#v_data.append(f_ledon[validate_size:])\n",
    "#for i in range(2):\n",
    "#    for j in range(validate_size):\n",
    "#        validate_labels.append(i)\n",
    "#        validate_data.append(v_data[i][j])\n",
    "#        \n",
    "#validate_data = np.array(validate_data)\n",
    "#validate_labels = np.array(validate_labels)\n",
    "\n",
    "\n",
    "# Shuffle the data sets so it isn't just 'all 1's then all 0's'...\n",
    "# This will help with the training, as our data is all linear for now\n",
    "training_data, training_labels = unison_shuffled_copies(training_data, training_labels)\n",
    "test_data, test_labels = unison_shuffled_copies(test_data, test_labels)\n",
    "#validate_data, validate_test = unison_shuffled_copies(validate_data, validate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-keyboard",
   "metadata": {},
   "source": [
    "So what have we done here? Well, we've built two lists for each dataset - a list of `_data` which are the arrays we got from the microcontroller, and an array of `_labels` which are just `0` if the data came from the `led_off.log` dataset, and `1` if it came from the `led_on.log` dataset. We then shuffle them concurrently to mix up the data for training. \n",
    "\n",
    "## Creating the TF Model\n",
    "\n",
    "So, with that done, let's build a model... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "double-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([ \n",
    "    keras.layers.Flatten(input_shape=(16,)), # using Flatten isn't necessary, but included as it's handy for building out.\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu), #started at 128, but we don't need that many -MC\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu), # Second layer for betterment of humanity... -MC\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax) # output '0' or '1' for LED off or on respectively -MC\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hybrid-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Lets save our current model state so we can reload it loater\n",
    "model.save_weights(\"model_data/pre-fit.weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-reporter",
   "metadata": {},
   "source": [
    "Let's walk through this a little; We are using a sequential Keras model - this just means that the model is linear, or 'in a line'. We're not doing funky stuff (like layer sharing or using a non-linear topology) so this is fine for us here.\n",
    "\n",
    "The first layer is a flattened 16 number input to the model. This just reads the input into the model - called the 'input tensor' to the model. \n",
    "\n",
    "For the curious, tensor is a generalisation of vector, but that isn't important right now... the important thing is that you you get the joke; \"The more you talk math to ML people, the _tensor_ they get...\" (_I'll see myself out._)\n",
    "\n",
    "There are then two hidden layers of size 64, with an output layer of size 2. The output layer will activate one node for 'LED is OFF' and the other for 'LED is ON', given by the fact we have two labels in our training data - again, this comes from an 'output tensor'.\n",
    "\n",
    "The hidden layers are just 'the layers that aren't input nor output' - there's nothing nefarious about them. The idea of using two layers is that this will improve our accuracy when training. \n",
    "\n",
    "The Netron diagram for this model is the following:\n",
    "\n",
    "![Netron TF diagram](media/LED_model.png)\n",
    "\n",
    "This model is _incredibly basic_ and yes, there are many, many improvements that can be made. But honestly? This is Proof of Concept (PoC) code! This is just to see if we can make it work, in any sense, without any refinements. So, we're just gonna leave that there and get on with training! \n",
    "\n",
    "## Training the model\n",
    "\n",
    "The training function in TensorFlow is `model.fit()` which takes our training data and training labels, determines the validation split, and then trains the data. \n",
    "\n",
    "Training a ML model is when each node in the network we defined above has a value, or weight, assigned. So, we have some array of 136 numbers that we want to then use in the manner described in the neural network definition to determine if the LED is ON or OFF. But, of course, this doesn't happen by itself - we have to train the model to get the output right! \n",
    "\n",
    "I won't go into the specifics here - it would take too long and others have written extensively on it! So I'll refer you to [Google's ML Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss) to see how they describe model training (as well as loads more!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooperative-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_data, training_labels, epochs=e_pochs, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-retail",
   "metadata": {},
   "source": [
    "Let's see how we did! We'll draw a graph detailing the loss (the penalty for the model making a bad prediction - basically, how much we had to tell the model off for getting it wrong) and accuracy (how accurate our model was) by looking at the data generated about it during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acknowledged-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss/accuracy')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Validation Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['accuracy']),\n",
    "           label='Train accuracy')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_accuracy']),\n",
    "           label = 'Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 2])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affected-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 540us/step - loss: 0.2331 - accuracy: 0.9845\n",
      "Accuracy on testdata: 98.4499990940094 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Accuracy on testdata:', test_acc * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-primary",
   "metadata": {},
   "source": [
    "The last cell loads the accuracy as a percentage overall... For the training data I have it's at 98.4% _and that ain't at all bad!_ Without any real work or jiggery-pokery, we have managed to get a model to 98% accuracy! Ace! \n",
    "\n",
    "## Refinements\n",
    "\n",
    "In short, not yet. This PoC is to focus on getting the model into a microcontroller, rather than building a perfect model... As such, 98% is more than good enough for our purposes, so let's get on with loading this onto the microcontroller!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-freedom",
   "metadata": {},
   "source": [
    "# Model Deployment on a Microcontroller\n",
    "\n",
    "First off, let's convert our TF model to a TF Lite model, making it nice and small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unique-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcpwfvv27/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"model_data/LED_model.tflite\", 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-budapest",
   "metadata": {},
   "source": [
    "## Model Quantisation\n",
    "\n",
    "Now, whilst the TF Lite model is, well, much lighter, it's still a bit big... As every machine learning engineer comes to ask, _\"does my model look big in this?\"_\n",
    "\n",
    "Even though our model _isn't actually that big_, you may want to develop a much more nuanced model, or a model with more layers or more inputs from bigger training sets, etc. etc. So we're going to assume that we want/need to quantise our TFLite model to make it fit onto a microcontroller. \n",
    "\n",
    "Here's the code we are using - we'll run through it after the break:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dominican-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpok03vrey/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpok03vrey/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Indicate that we want to perform the default optimizations,\n",
    "# which include quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Define a generator function that provides our test data's x values\n",
    "# as a representative dataset, and tell the converter to use it\n",
    "def representative_dataset_generator():\n",
    "    for value in test_data:\n",
    "        # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
    "        yield [np.array(value, dtype=np.float32, ndmin=2)]\n",
    "\n",
    "converter.representative_dataset = representative_dataset_generator\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"model_data/LED_model_quantized.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-pierre",
   "metadata": {},
   "source": [
    "## What is a quantised model?\n",
    "\n",
    "Here is the Netron diagram for the resultant quantised model:\n",
    "\n",
    "![quantised model diagram](media/LED_model_quantized.png)\n",
    "\n",
    "You'll notice - _it's exactly the same as the other one_ except for the addition of the `quantise`/`dequantise` steps at the top/tail respectively. So what is going on? Well, we're essentially converting the model from the bold, `float32` inspired world of \"I have a CISC CPU and a power supply measured in tens-to-hundreds of Watts\" down to something that, essentially, can be powered by a potato or two (well, more likely a few dozen lemons... they have more potential energy).\n",
    "\n",
    "To do this, the model is reconfigured to use `int8` as its base - yes, you read that right. That makes it monumentally more friendly to data types on microcontrollers... but surely we have to do something to our input data? And, well, you're right.\n",
    "\n",
    "Fundamentally, our model has been squeezed, so we need to squeeze the inputs/outputs a little to recover the original state of the model. Note that the size of the model has gone from 23,564 bytes down to just 8,864 bytes - for the curious, that's a 62.4% reduction! Hopefully this gives justification to the why and wherefore that quantized models exist, and are used when doing embedded TinyML.\n",
    "\n",
    "The actual [TensorFlow int8 quantised model specification](https://www.tensorflow.org/lite/performance/quantization_spec) details the specifics of what is going on, but the most important part is the way in which the inputs are scaled:\n",
    "\n",
    "![equation](http://www.sciweavers.org/tex2img.php?eq=real%5C_val%20%3D%20%28int8%5C_val%20-%20zero%5C_point%29%20%5Ctimes%20scale&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n",
    "\n",
    "Which yields the following calculation for our inputs:\n",
    "\n",
    "![equation 2](http://www.sciweavers.org/tex2img.php?eq=int8%5C_val%20%3D%20%28real%5C_val%20%20%2F%20%20scale%20%29%20%2B%20zero%5C_point&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=)\n",
    "\n",
    "Let's first process the model and make it ready..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "finished-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsigned char model_data_LED_model_quantized_tflite[] = {\r\n",
      "  0x24, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\r\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00,\r\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00,\r\n",
      "  0x12, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0xfc, 0x21, 0x00, 0x00,\r\n",
      "  0x40, 0x18, 0x00, 0x00, 0x28, 0x18, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\r\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\r\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x08, 0x00, 0x00, 0x00,\r\n",
      "  0x08, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\r\n",
      "  0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f,\r\n",
      "...\r\n",
      "  0x00, 0x00, 0x00, 0x06, 0x02, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\r\n",
      "  0xc8, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x72, 0x72, 0x00, 0x00, 0x00,\r\n",
      "  0xf0, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x19, 0x02, 0x00, 0x00, 0x00,\r\n",
      "  0x19, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x07, 0x00, 0x00, 0x00,\r\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\r\n",
      "  0x04, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00,\r\n",
      "  0x07, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x00, 0x00,\r\n",
      "  0x00, 0x00, 0x00, 0x16, 0x16, 0x00, 0x00, 0x00\r\n",
      "};\r\n",
      "unsigned int model_data_LED_model_quantized_tflite_len = 8864;\r\n"
     ]
    }
   ],
   "source": [
    "!xxd -i model_data/LED_model_quantized.tflite > model_data/LED_model_quantized.cc\n",
    "!head -n 10 model_data/LED_model_quantized.cc && echo \"...\" && tail -n 10 model_data/LED_model_quantized.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-acoustic",
   "metadata": {},
   "source": [
    "## Loading the Model into the Arduino\n",
    "\n",
    "We're now ready to load the model onto the Arduino Nano 33 Sense! \n",
    "\n",
    "### Overview of the project files\n",
    "\n",
    "So now that we have our `LED_model_quantized.cc`, let's look at how to load this. First up, here's a quick overview of the files in the `Arduino_CurrentSense_ML` directory:\n",
    "\n",
    "* `arduino_constants.cpp` - Some constants used in the project.\n",
    "* `arduino_main.cpp` - The `setup()` and `loop()` functions used by Arduino IDE\n",
    "* `arduino_output_handler.cpp` - The output handler for the output from the model inference.\n",
    "* `constants.h` - More constants.\n",
    "* `current_ML.ino` - the main project file! Sets up the model, loads the data, passes the output to the `output_handler`.\n",
    "* `main_functions.h` - main function headers\n",
    "* `model.cpp` - the model itself! Copied from `LED_model_quantized.cc`\n",
    "* `model.h` - model header definitions\n",
    "* `output_handler.h` - output handler header definitions.\n",
    "\n",
    "If you haven't already, copy the model details, the array and size variable, from `LED_model_quantized.cc` into `model.cpp`, ensuring to fix the variable names in `current_ML.ino` if required.\n",
    "\n",
    "### Walking through the Firmware Code\n",
    "\n",
    "We won't go through the whole of the code in the project, but will outline the main part! \n",
    "\n",
    "The `setup()` function in `current_ML.ino` is almost identical to the `hello_world` TFLite example code - it loads the model as `g_model`, finds the input/output tensors, stores their addresses, etc. etc. It also setups up the INA219 device, and yes, employs my _dirrrrty hack_ from earlier :P \n",
    "\n",
    "We have some other functions to load the data - `load_data()` function is our loader:\n",
    "\n",
    "```c\n",
    "void load_data(const int8_t * data, TfLiteTensor * input)\n",
    "{\n",
    "    for (int i = 0; i < 16; ++i)\n",
    "    {\n",
    "        input->data.int8[i] = data[i];\n",
    "    }\n",
    "}\n",
    "```\n",
    "In the main `loop()` we have the same function loop as we did before, but this time adjusting based on the pre-loaded scale and zero point that TF Lite calculated for us when we quantized the model. These are stored in `input->params.scale` and `input->params.zero_point` respectively.\n",
    "```c    \n",
    "int param;\n",
    "for(i=0;i < 16; i += 1){\n",
    "    param = ina219.getCurrent_raw();\n",
    "    // scale the input...\n",
    "    curr_array[i] = param / input->params.scale + input->params.zero_point;\n",
    "}\n",
    "load_data(curr_array, input);\n",
    "```\n",
    "\n",
    "We run the model on the input tensor we have setup by running `TfLiteStatus invoke_status = interpreter->Invoke();`, and if there are no errors, we then get the outputs from the inference (which are `float32`) and pass these to `HandleOutput`:\n",
    "```c\n",
    "float y_1 = output->data.f[0]; // get last byte of output...\n",
    "float y_2 = output->data.f[1];\n",
    "HandleOutput(error_reporter, y_1, y_2);\n",
    "```\n",
    "\n",
    "From here, we process these outputs as follows:\n",
    "```c\n",
    "void HandleOutput(tflite::ErrorReporter* error_reporter, float x_1, float x_2) {\n",
    "  // Do this only once\n",
    "  if (!initialized) {\n",
    "    // Set the LED pin to output\n",
    "    pinMode(led, OUTPUT);\n",
    "    initialized = true;\n",
    "  }\n",
    "\n",
    "  bool output = (x_2 == 0) ? LOW : HIGH; // we'll just use x_2, but can add for x_1 as well... \n",
    "  // if the previous outputs are the same as the current, then the LED is likely on...\n",
    "  // this is to remove noisey false readings from the model...\n",
    "  if (prev_out[0] == prev_out[1] && prev_out[1] == output){\n",
    "    digitalWrite(led, output);\n",
    "  }\n",
    "\n",
    "  // Log the current brightness value for display in the Arduino plotter\n",
    "  TF_LITE_REPORT_ERROR(error_reporter, \"LED guess: %d\\n\", output);\n",
    "  prev_out[0] = prev_out[1];\n",
    "  prev_out[1] = output;\n",
    "}\n",
    "```\n",
    "\n",
    "The output handler looks at the current and previous two outputs and determines if the LED is ON or OFF based on these three all agreeing. This is to clean up the siginal which is pretty noisey by itself. The result, though, is a reasonably good detection for the LED being powered or not, solely from inference on data from stock, off the shelf parts! Just add a touch of ML..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-nowhere",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Well, in case you missed it, it works! It's flaky as anything, as seen by the intermitten blinking, but it does work! Here's a PoC GIF for the curious:\n",
    "\n",
    "![PoC](media/proof_of_concept.gif)\n",
    "\n",
    "## Known Issues\n",
    "\n",
    "So, there are some things I have noticed whilst playing with this model and deploying it. We'll take this as a 'things you can try to fix for yourself' (the lab has some WIP fixes for this and other projects on the way).\n",
    "\n",
    "**1** Sometimes, the model inverts - it will activate on the LED being OFF, and never activate on being ON. Moving the target around actually seems to affect this, so my guess is there is some response to parasitic capacitance. The fix is likely - use shorter power leads to the target! (**Update** - this is mostly fixed now -MC)\n",
    "\n",
    "**2** The code needs a lot of reworking - there are many areas where speed can be improved or things can be done better. Feel free to make a PR!\n",
    "\n",
    "## Why an INA219?\n",
    "\n",
    "It's probably natural to ask _But why an INA219? Why not an ADC that's built in?!?_ If you've played around with electronics, you've probably built a current monitor with a microcontroller, and might think that the INA219 is misplaced or overkill to use one... Well, there are a few reasons we consider for using the INA219. \n",
    "\n",
    "First up, I didn't want to have to start adding requirements for a solid `AREF` for a start - yes, you can get low-dropout regulators like the `LM2937` or similar, and yes, these would do the job, but it's more parts, more things to setup, and it could complicate the setup.\n",
    "\n",
    "Second reason is that of specialisation - the INA219 is specifically designed for this task! And the breakout boards are inexpensive, easy to come by, and readily available. Yes, the ADCs are already there, but they would require extra work to meet the requriements for the things the INA219 already does. \n",
    "\n",
    "Lastly, that of portability - in theory, using a part that communicates in I2C means that you don't _need_ an Arduino Nano 33 Sense to make this project work! In theory, you can plug in any microcontroller, re-run the training code, recompile and redeploy in short order; all without having to worry about ADC specifics for a different microcontroller.\n",
    "\n",
    "## Future Work\n",
    "\n",
    "This idea can easily be extended to other sensors and for other target types! We wanted to show that a roughly 2mA difference in operation could still be identifiable without any major reworking of PCBs or parts, effectively running this off the shelf. This design could be quickly extended to monitor USB current, Hall Effect sensors, or other unusual situations where a TinyML model could do something useful or cool! \n",
    "\n",
    "## Further Reading\n",
    "\n",
    "There is a growing body of resources for TinyML, but the most relevant reference as of writing this PoC (Mar'21) is \"TinyML\" by Pete Warden and Daniel Situnayake, published by O'Reilly - \n",
    "\n",
    "[https://www.oreilly.com/library/view/tinyml/9781492052036/](https://www.oreilly.com/library/view/tinyml/9781492052036/)\n",
    "\n",
    "For those who want to just 'dive in', the TensorFlow Lite website has a plethora of information, and the GitHub for TF Lite for Micro Controllers has many example code projects and jupyter notebooks to work through, explaining how 'magic wand' and 'watchword' models work, which are really good examples: \n",
    "\n",
    "[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro)\n",
    "\n",
    "As I mentioned before, [Google's ML Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss) is another really good resource in case you have more general or background quesitons about machine learning.\n",
    "\n",
    "If you would like some more formal qualifications that deal with Embedded/TinyML, have a look at the following:\n",
    "* [Harvard's Embedded ML Course](https://www.edx.org/professional-certificate/harvardx-tiny-machine-learning) on EDX\n",
    "* [Edge Impulse's TinyML Coruse](https://www.coursera.org/learn/introduction-to-embedded-machine-learning) on Coursera\n",
    "\n",
    "**Thanks for your attention, and Happy Hacking!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
